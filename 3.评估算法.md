# 评估算法
评估算法是对算法模型进行验证，就是估计算法在预测新数据的时候能达到什么程度。以下是四种不同的分离数据集的方法：
+ 分离训练数据集和评估数据集
+ K折交叉验证分离
+ 弃一交叉验证分离
+ 重复随机评估、训练数据集分离

## 1.分离训练数据集和评估数据集
简单的将评估数据集和训练数据集完全分开，前者用来评估模型，后者用来生成模型。

```
test_size = 0.33
seed = 4 #数据随机的粒度
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)
model = LogisticRegression()
model.fit(X_train, Y_train)
result = model.score(X_test, Y_test)
print("算法评估结果：%.3f%%" % (result * 100))
```

## 2.K折交叉验证分离
交叉验证是用来验证分类器的性能的一种统计分析方法，K折交叉验证是将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集作为训练集，得到K个模型，再用这K个模型最终的验证集的分类准确率的平均数作为此K折交叉验证下分类器的性能指标。K一般大于等于2，实际操作时一般从3开始取值，只有在原始数据集和数据量小的时候才会尝试取2。**K折交叉验证可以有效避免过学习及欠学习状态的发生，最后得到的结果也比较具有说服力。** 通常情况下，K取3、5、10.不清楚时选择K=10.

```
num_folds =10
seed = 7
kfold = KFold(n_splits=num_folds, random_state=seed)
model = LogisticRegression()
result = cross_val_score(model, X, Y, cv=kfold)
print("算法评估结果：%.3f%%(%.3f%%)" % (result.mean() * 100, result.std() * 100))
## 得分及标准方差
```

## 3.弃一交叉验证分离
算法与K折交叉验证类似，只不过将K组变成了N组，N为样本数，拿出一个作为验证集，其余均作为训练集。有以下优点：
+ 每次训练几乎使用所有样本，所得评估结果较为可靠。
+ 没有随机因素影响实验数据，确保过程是可复制
  
缺点是计算成本高，花费大量时间，可以用并行化计算减少计算所需时间

```
loocv = LeaveOneOut()
model = LogisticRegression()
result = cross_val_score(model, X, Y, cv=loocv)
print("算法评估结果：%.3f%% (%.3f%%)" % (result.mean() * 100, result.std() * 100)
```

## 4.重复随机评估、训练数据集分离
用K折交叉验证，随机分离数据为训练数据集和评估数据集。

```
n_splits = 10
test_size = 0.33
seed = 7
kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)
model = LogisticRegression()
result = cross_val_score(model, X, Y, cv=kfold)
print("算法评估结果：%.3f%% (%.3f%%)" % (result.mean() * 100, result.std() * 100))