# 一、分类算法矩阵
评估分类算法的评估矩阵：
+ 分类准确度
+ 对数损失函数
+ 混淆矩阵
+ 分类报告
  
## 1.分类准确度
分类准确度就是算法自动分类正确的样本数除以所有的样本数得出的结果。通常，准确度越高，分类器越好。**这是分类算法中最常见的，也最易被误用的评估参数。** 比如说预测某地区某天的地震，假设有一堆的特征作为地震分类的属性，类别只有地震和不地震，这样的分类准确度可以高达99%，但真正地震时这个分类器却毫无察觉，因为数据分布不均衡，发生地震的样本数据太少，完全错分类别为地震却依然可以达到很高的准确度，忽视了需要关注的事实和现象。

```
num_folds = 10
seed = 7
kfold = KFold(n_splits_=num_folds, random_state=seed)
model = LogisticRegression()
result = cross_val_score(model, X, Y, cv=kfold)
print("算法评估结果准确度：%.3f(%.3f)" % (result.mean(), result.std()))
```

## 2.对数损失函数
在逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，再取对数、求极值。而逻辑回归并没有求似然函数的极值，而是把极大化当作一种思想，进而推导出它的经验风险函数为：最小化负的似然函数[max F(y,f(x)) -> min -F(y,f(x))].从损失函数的视角来看，它就成了对数损失函数。对数损失函数越小，模型就越好，而且使损失函数尽量是一个凸函数，便于收敛计算.

```
num_folds = 10
seed = 7
kfold = KFold(n_splits=num_folds, random_state=seed)
model = LogisticRegression()
scoring = 'neg_log_loss'
result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('Logloss %.3f (%.3f)' % (result.mean(), result.std()))
```

## 3.AUC图
ROC（受试者工作特征曲线）和AUC（ROC曲线下面积）是评价分类器的指标，通常，AUC的值介于0.5到1.0之间，AUC的值越大，诊断准确性越高。

分类| 真|假
--|:--:|--:
分类 | 1 | 0
1 | TP | FP
0|FN|TN

**敏感性指标：**
**真正类率  TPR=TP/（TP+FN）**
**负正类率  FPR=FP/（FP+TN）**
**真负类率  TNR=TN/（FP+TN）**

```
num_folds = 10
seed = 7
kfold =KFold(n_splits=num_folds, random_state=seed)
model = LogisticRegression()
scoring = 'roc_auc'
result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('AUC %.3f (%.3f)' % (result.mean(), result.std()))
```

## 4.混淆矩阵
与AUC类似，假设有150个样本，分成3类，得到混淆矩阵如下，每行50样本，第一行说明类1的50样本中43个分类正确，5个错分为类2，2个错分为类3.

预测/实际|类1|类2|类3
--|:--:|--|--
类1|43|5|2
类2|2|45|3
类3|0|1|49

```
test_size = 0.33
seed = 4
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)
model = LogisticRegression()
model.fit(X_train, Y_train)
predicted = model.predict(X_test)
matrix = confusion_matrix(Y_test, predicted)
classes = ['0', '1']
dataframe = pd.DataFrame(data=matrix, index=classes, columns=classes)
print(dataframe)
```

## 5.分类报告
通过Classification_report()方法计算出精确率（precision）、召回率（recall）、F1值（F1-score）和样本数目（support）

 **精确率公式 P=TP/（TP+FP）**
  所有被检索到的项目中应该被检索到的项目占的比例


 **召回率公式 R=TP/(TP+FN)**
所有检索到的项目占所有应该检索到的项目的比例

**F1值 2F1=P+R**
精确率和召回率的调和均值

```
test_size = 0.33
seed = 4
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)
model = LogisticRegression()
model.fit(X_train, Y_train)
predicted = model.predict(X_test)
report = Classification_report(Y_test, predicted)
print(report)
```

# 二、回归算法矩阵

## 1.平均绝对误差
平均绝对误差是所有单个观测值与算术平均值的偏差的绝对值的平均值。不会正负相互抵消，更好地反映预测值误差情况。

```
n_splits = 10 
seed = 7
kfold = KFold(n_splits=n_splits, random_state=seed)
model = LogisticRegression()
scoring = 'neg_mean_absolute_error'
result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('MAE: %.3f (%.3f)' % (result.mean(), result.std()))
```

## 2.均方误差
评价数据的变化程度

```
n_splits = 10 
seed = 7
kfold = KFold(n_splits=n_splits, random_state=seed)
model = LogisticRegression()
scoring = 'neg_mean_squared_error'
result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('MSE: %.3f (%.3f)' % (result.mean(), result.std()))
```

## 3.决定系数
决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例。非负的统计量，取值0<=R*R<=1,随抽样变动而变动。

```
n_splits = 10 
seed = 7
kfold = KFold(n_splits=n_splits, random_state=seed)
model = LogisticRegression()
scoring = 'R2'
result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('R2: %.3f (%.3f)' % (result.mean(), result.std()))
```


